# Домашнее задание к занятию "`Домашнее задание к занятию «Микросервисы: подходы`" - `Шатый Константин`

# Задача 1: Обеспечить разработку

Решение для обеспечения процесса разработки

Предлагается использовать комбинацию следующих инструментов:

GitHub - для хранения исходного кода.

GitHub Actions - для обеспечения непрерывной интеграции и непрерывной поставки (CI/CD).

Jenkins - для расширенных возможностей CI/CD, кастомных шагов и управления сборками.

Docker - для создания и управления собственными докер-образами.

HashiCorp Vault - для безопасного хранения секретных данных.


# Обоснование выбора

### GitHub

Облачная система: GitHub - это облачная платформа, что соответствует требованию об облачной системе.

Система контроля версий Git: GitHub использует Git для контроля версий.

Репозиторий на каждый сервис: GitHub позволяет легко управлять множеством репозиториев, что идеально для микросервисной архитектуры.

### GitHub Actions

Запуск сборки по событию из системы контроля версий: GitHub Actions позволяет автоматически запускать сборки по событиям, таким как push или pull request.

Запуск сборки по кнопке с указанием параметров: В GitHub Actions можно настроить ручной запуск workflows с указанием параметров.

Возможность создания шаблонов для различных конфигураций сборок: Workflows в GitHub Actions могут быть переиспользуемыми и параметризуемыми, что позволяет создавать шаблоны для различных конфигураций сборок.

Несколько конфигураций для сборки из одного репозитория: GitHub Actions поддерживает множественные workflows для одного репозитория, что позволяет использовать различные конфигурации сборки.

Кастомные шаги при сборке: GitHub Actions поддерживает кастомные шаги через использование YAML-конфигураций.

### Jenkins

Возможность развернуть агентов сборки на собственных серверах: Jenkins позволяет легко разворачивать и управлять агентами сборки на собственных серверах.

Возможность параллельного запуска нескольких сборок и тестов: Jenkins поддерживает параллельное выполнение задач, что ускоряет процесс сборки и тестирования.

### Docker

Собственные докер-образы для сборки проектов: Docker позволяет создавать и использовать собственные образы для сборки и тестирования проектов.

Кастомные шаги при сборке: Использование Docker в CI/CD пайплайнах позволяет выполнять кастомные шаги, необходимые для сборки и тестирования.

### HashiCorp Vault

Безопасное хранение секретных данных (пароли, ключи доступа): Vault обеспечивает безопасное хранение и управление секретными данными, такими как пароли и ключи доступа.

Взаимодействие инструментов

### GitHub:

Каждый микросервис имеет свой отдельный репозиторий.

Исходный код хранится в GitHub.

### GitHub Actions:

Автоматический запуск workflows при событиях в репозитории (push, pull request).

Возможность ручного запуска сборок с указанием параметров.

Использование параметризуемых workflows для различных конфигураций сборок.

Интеграция с Docker для использования собственных образов.

### Jenkins:

Интеграция с GitHub для запуска сборок по webhook.

Развертывание агентов на собственных серверах для выполнения задач.

Параллельное выполнение сборок и тестов.

Использование Docker для выполнения кастомных шагов и обеспечения изолированных сред.

### Docker:

Создание и управление образами для сборки и тестирования.

Использование Docker Compose для оркестрации многокомпонентных приложений.

### HashiCorp Vault:

Безопасное хранение и управление секретами.

Интеграция с Jenkins и GitHub Actions для безопасного доступа к секретным данным.

Пример пайплайна

### GitHub Actions Workflow:

Триггерится при push или pull request.

Запускает сборку и тестирование в контейнерах Docker.

При необходимости, передает управление Jenkins для выполнения сложных задач.

### Jenkins Pipeline:

Получает исходный код из GitHub.

Запускает сборочные и тестовые задачи параллельно на агентах.

Использует Docker образы для выполнения задач.

Хранит и управляет секретными данными с помощью Vault.

### HashiCorp Vault:

Секреты используются в Jenkins и GitHub Actions для доступа к необходимым ресурсам.

# Заключение

Такое комплексное решение, объединяющее GitHub, GitHub Actions, Jenkins, Docker и HashiCorp Vault, обеспечивает гибкость, безопасность и масштабируемость процесса разработки и эксплуатации в микросервисной архитектуре.


# Задача 2: Логи

### Решение для обеспечения сбора и анализа логов в микросервисной архитектуре

Для организации процесса сбора и анализа логов в микросервисной архитектуре с соблюдением всех требований, предлагается использовать комбинацию следующих инструментов:

Fluentd - для сбора и транспортировки логов.

Elasticsearch - для хранения и поиска по логам.

Kibana - для визуализации и анализа логов.

# Обоснование выбора

### Fluentd

Сбор логов в центральное хранилище со всех хостов: Fluentd может собирать логи с различных хостов и передавать их в центральное хранилище.

Минимальные требования к приложениям, сбор логов из stdout: Fluentd может собирать логи непосредственно из stdout, что минимизирует требования к приложениям.

Гарантированная доставка логов до центрального хранилища: Fluentd обеспечивает надежную доставку логов с использованием механизмов буферизации и повторных попыток при сбоях.

### Elasticsearch

Обеспечение поиска и фильтрации по записям логов: Elasticsearch предоставляет мощные возможности для поиска и фильтрации данных, что идеально подходит для работы с логами.

Хранение логов в центральном хранилище: Elasticsearch эффективно справляется с хранением больших объемов данных и позволяет масштабировать систему по мере необходимости.

### Kibana

Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов: Kibana предоставляет интуитивно понятный интерфейс для анализа и визуализации логов, а также позволяет разработчикам выполнять поиск по записям логов.

Возможность дать ссылку на сохранённый поиск по записям логов: Kibana поддерживает создание и сохранение поисковых запросов, а также предоставляет возможность делиться ссылками на сохраненные поиски.

Взаимодействие инструментов

## Fluentd:

Устанавливается на каждом хосте, обслуживающем систему.

Считывает логи из stdout (и других источников, если необходимо) и передает их в Elasticsearch.

Настраивается для надежной доставки логов, используя буферизацию и повторные попытки в случае сбоев.

### Elasticsearch:

Получает логи от Fluentd и сохраняет их в индексы.

Обеспечивает быстрый поиск и фильтрацию логов с использованием запросов.

### Kibana:

Подключается к Elasticsearch для получения данных.

Предоставляет интерфейс для визуализации, анализа и поиска по логам.

Позволяет создавать дашборды и сохраненные поиски, которыми можно делиться через ссылки.

# Пример конфигурации

### Fluentd Configuration:

Настраивается для сбора логов из stdout всех микросервисов.

Настраивается для отправки логов в Elasticsearch с использованием соответствующих плагинов.

Настраивается для обеспечения буферизации и повторных попыток в случае сбоев.

<source>

  @type forward
  
  port 24224
  
  bind 0.0.0.0
  
</source>

<match **>

  @type elasticsearch
  
  host elasticsearch-host
  
  port 9200
  
  logstash_format true
  
  buffer_type file
  
  buffer_path /var/log/fluentd-buffers/
  
  flush_interval 5s
  
</match>

### Elasticsearch Configuration

Настраивается для получения логов от Fluentd.

Настраивается для оптимального хранения и индексации логов.

network.host: 0.0.0.0
discovery.type: single-node

### Kibana Configuration:

Подключается к Elasticsearch для получения данных.

Настраивается для предоставления интерфейса разработчикам для поиска и анализа логов.

server.host: "0.0.0.0"
elasticsearch.hosts: ["http://elasticsearch-host:9200"]

# Заключение

Такое комплексное решение, объединяющее Fluentd, Elasticsearch и Kibana, обеспечивает централизованный сбор, надежную доставку и эффективный анализ логов в микросервисной архитектуре. Оно также предоставляет интуитивно понятный интерфейс для разработчиков и возможность делиться сохраненными поисками, что соответствует всем предъявленным требованиям.

# Задача 3: Мониторинг

Для организации процесса мониторинга хостов и сервисов в микросервисной архитектуре с соблюдением всех требований, предлагается использовать комбинацию следующих инструментов:

Prometheus - для сбора и хранения метрик.

Node Exporter - для сбора метрик состояния хостов.

cAdvisor - для сбора метрик контейнеров и потребляемых ресурсов.

Grafana - для визуализации метрик и настройки панелей.

# Обоснование выбора

### Prometheus

Сбор метрик со всех хостов, обслуживающих систему: Prometheus эффективно собирает метрики с различных источников.

Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network: Prometheus может интегрироваться с Node Exporter для сбора этих метрик.

Сбор метрик, специфичных для каждого сервиса: Prometheus поддерживает кастомные метрики, которые могут быть экспонированы каждым сервисом.

Гарантированная доставка метрик до центрального хранилища: Prometheus использует pull-модель, что обеспечивает надежность сбора метрик.

### Node Exporter

Сбор метрик состояния ресурсов хостов: Node Exporter собирает метрики CPU, RAM, HDD и Network, предоставляя информацию о состоянии хостов.

### cAdvisor

Сбор метрик потребляемых ресурсов для каждого сервиса: cAdvisor собирает метрики контейнеров, включая CPU, RAM, HDD и Network, что позволяет отслеживать потребление ресурсов каждым сервисом.
### Grafana

Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию: Grafana предоставляет мощные возможности для создания запросов и агрегации данных из Prometheus.

Пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы: Grafana позволяет настраивать и сохранять дашборды для мониторинга различных аспектов системы.

Взаимодействие инструментов

### Node Exporter:

Устанавливается на каждом хосте.

Собирает метрики состояния ресурсов (CPU, RAM, HDD, Network).

Экспонирует метрики, которые собираются Prometheus.

### cAdvisor:

Запускается на каждом хосте с контейнерами.

Собирает метрики потребляемых ресурсов (CPU, RAM, HDD, Network) для каждого контейнера.

Экспонирует метрики, которые собираются Prometheus.

### Prometheus:

Конфигурируется для сбора метрик с Node Exporter, cAdvisor и кастомных метрик, экспонируемых сервисами.

Хранит собранные метрики и предоставляет интерфейс для выполнения запросов.

### Grafana:

Подключается к Prometheus для получения данных.

Предоставляет интерфейс для создания и настройки дашбордов.

Позволяет выполнять запросы и агрегацию данных, а также сохранять и делиться дашбордами.

# Пример конфигурации

### Prometheus Configuration:

global:

  scrape_interval: 15s

scrape_configs:

   job_name: 'node_exporter'
   
    static_configs:
    
      - targets: ['node-exporter-host:9100']

   job_name: 'cadvisor'
   
    static_configs:
    
      - targets: ['cadvisor-host:8080']

   job_name: 'my_service'
   
    static_configs:
    
      - targets: ['my-service-host:8080']

### Node Exporter:

Устанавливается и запускается на каждом хосте.

Экспонирует метрики на порту 9100.

### cAdvisor:

Запускается как Docker-контейнер на каждом хосте с контейнерами.

Экспонирует метрики на порту 8080.

### Grafana:

Устанавливается и конфигурируется для подключения к Prometheus.

Создаются дашборды для визуализации метрик состояния хостов, потребляемых ресурсов и специфичных метрик сервисов.

# Заключение

Такое комплексное решение, объединяющее Prometheus, Node Exporter, cAdvisor и Grafana, обеспечивает централизованный сбор, надежную доставку и эффективный анализ метрик хостов и сервисов в микросервисной архитектуре. Оно также предоставляет интуитивно понятный интерфейс для разработчиков и возможность настройки дашбордов, что соответствует всем предъявленным требованиям.
